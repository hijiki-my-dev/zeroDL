{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from dataset import sequence\n",
    "from common.optimizer import Adam\n",
    "from common.trainer import Trainer\n",
    "from common.util import eval_seq2seq\n",
    "from attention import AttentionSeq2seq2\n",
    "from ch7.seq2seq import Seq2seq\n",
    "from ch7.peeky_seq2seq import PeekySeq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 29) (5000, 29)\n"
     ]
    }
   ],
   "source": [
    "# データ読み込み\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data(\"dataset/date.txt\")\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 29) (45000, 11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(dict, 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape, t_train.shape)\n",
    "type(char_to_id), char_to_id[\"s\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ハイパーパラメータ\n",
    "vocab_size = len(char_to_id)\n",
    "wordvec_size = 16\n",
    "hidden_size = 256\n",
    "batch_size = 128\n",
    "max_epoch = 10\n",
    "max_grad = 5.0\n",
    "\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttentionSeq2seq2(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trainer] batch_x: (128, 29)\n",
      "[Trainer] batch_t: (128, 11)\n",
      "[Seq2seq.forward] xs: (128, 29), ts: (128, 11)\n",
      "[AttentionDecoder.forward] out: (128, 10, 16)\n",
      "[AttentionDecoder.forward] dec_hs: (128, 10, 256) <- この長さが理想の10倍だった\n",
      "[AttentionDecoder.forward] c: (128, 10, 256)\n",
      "[AttentionDecoder.forward] out: (128, 10, 512)\n",
      "[TimeAffine.forward] x: (128, 10, 512)\n",
      "[TimeAffine.forward] rx: (1280, 512)\n",
      "[TimeAffine.forward] return: (128, 10, 59)\n",
      "[AttentionDecoder.forward] score: (128, 10, 59)\n",
      "[TimeSoftmaxWithLoss] xs: (128, 10, 59)\n",
      "[Seq2seq] dout: (128, 10, 59)\n",
      "[TimeAffine.backward] return dx: (128, 10, 512)\n",
      "[TimeAttention.backward] dout: (128, 10, 256)\n",
      "| epoch 1 |  iter 1 / 351 | time 0[s] | loss 4.08\n",
      "[Trainer] batch_x: (128, 29)\n",
      "[Trainer] batch_t: (128, 11)\n",
      "[Seq2seq.forward] xs: (128, 29), ts: (128, 11)\n",
      "[AttentionDecoder.forward] out: (128, 10, 16)\n",
      "[AttentionDecoder.forward] dec_hs: (128, 10, 256) <- この長さが理想の10倍だった\n",
      "[AttentionDecoder.forward] c: (128, 10, 256)\n",
      "[AttentionDecoder.forward] out: (128, 10, 512)\n",
      "[TimeAffine.forward] x: (128, 10, 512)\n",
      "[TimeAffine.forward] rx: (1280, 512)\n",
      "[TimeAffine.forward] return: (128, 10, 59)\n",
      "[AttentionDecoder.forward] score: (128, 10, 59)\n",
      "[TimeSoftmaxWithLoss] xs: (128, 10, 59)\n",
      "[Seq2seq] dout: (128, 10, 59)\n",
      "[TimeAffine.backward] return dx: (128, 10, 512)\n",
      "[TimeAttention.backward] dout: (128, 10, 256)\n",
      "[Trainer] batch_x: (128, 29)\n",
      "[Trainer] batch_t: (128, 11)\n",
      "[Seq2seq.forward] xs: (128, 29), ts: (128, 11)\n",
      "[AttentionDecoder.forward] out: (128, 10, 16)\n",
      "[AttentionDecoder.forward] dec_hs: (128, 10, 256) <- この長さが理想の10倍だった\n",
      "[AttentionDecoder.forward] c: (128, 10, 256)\n",
      "[AttentionDecoder.forward] out: (128, 10, 512)\n",
      "[TimeAffine.forward] x: (128, 10, 512)\n",
      "[TimeAffine.forward] rx: (1280, 512)\n",
      "[TimeAffine.forward] return: (128, 10, 59)\n",
      "[AttentionDecoder.forward] score: (128, 10, 59)\n",
      "[TimeSoftmaxWithLoss] xs: (128, 10, 59)\n",
      "[Seq2seq] dout: (128, 10, 59)\n",
      "[TimeAffine.backward] return dx: (128, 10, 512)\n",
      "[TimeAttention.backward] dout: (128, 10, 256)\n",
      "[Trainer] batch_x: (128, 29)\n",
      "[Trainer] batch_t: (128, 11)\n",
      "[Seq2seq.forward] xs: (128, 29), ts: (128, 11)\n",
      "[AttentionDecoder.forward] out: (128, 10, 16)\n",
      "[AttentionDecoder.forward] dec_hs: (128, 10, 256) <- この長さが理想の10倍だった\n",
      "[AttentionDecoder.forward] c: (128, 10, 256)\n",
      "[AttentionDecoder.forward] out: (128, 10, 512)\n",
      "[TimeAffine.forward] x: (128, 10, 512)\n",
      "[TimeAffine.forward] rx: (1280, 512)\n",
      "[TimeAffine.forward] return: (128, 10, 59)\n",
      "[AttentionDecoder.forward] score: (128, 10, 59)\n",
      "[TimeSoftmaxWithLoss] xs: (128, 10, 59)\n",
      "[Seq2seq] dout: (128, 10, 59)\n",
      "[TimeAffine.backward] return dx: (128, 10, 512)\n",
      "[TimeAttention.backward] dout: (128, 10, 256)\n",
      "[Trainer] batch_x: (128, 29)\n",
      "[Trainer] batch_t: (128, 11)\n",
      "[Seq2seq.forward] xs: (128, 29), ts: (128, 11)\n",
      "[AttentionDecoder.forward] out: (128, 10, 16)\n",
      "[AttentionDecoder.forward] dec_hs: (128, 10, 256) <- この長さが理想の10倍だった\n",
      "[AttentionDecoder.forward] c: (128, 10, 256)\n",
      "[AttentionDecoder.forward] out: (128, 10, 512)\n",
      "[TimeAffine.forward] x: (128, 10, 512)\n",
      "[TimeAffine.forward] rx: (1280, 512)\n",
      "[TimeAffine.forward] return: (128, 10, 59)\n",
      "[AttentionDecoder.forward] score: (128, 10, 59)\n",
      "[TimeSoftmaxWithLoss] xs: (128, 10, 59)\n",
      "[Seq2seq] dout: (128, 10, 59)\n",
      "[TimeAffine.backward] return dx: (128, 10, 512)\n",
      "[TimeAttention.backward] dout: (128, 10, 256)\n",
      "[Trainer] batch_x: (128, 29)\n",
      "[Trainer] batch_t: (128, 11)\n",
      "[Seq2seq.forward] xs: (128, 29), ts: (128, 11)\n",
      "[AttentionDecoder.forward] out: (128, 10, 16)\n",
      "[AttentionDecoder.forward] dec_hs: (128, 10, 256) <- この長さが理想の10倍だった\n",
      "[AttentionDecoder.forward] c: (128, 10, 256)\n",
      "[AttentionDecoder.forward] out: (128, 10, 512)\n",
      "[TimeAffine.forward] x: (128, 10, 512)\n",
      "[TimeAffine.forward] rx: (1280, 512)\n",
      "[TimeAffine.forward] return: (128, 10, 59)\n",
      "[AttentionDecoder.forward] score: (128, 10, 59)\n",
      "[TimeSoftmaxWithLoss] xs: (128, 10, 59)\n",
      "[Seq2seq] dout: (128, 10, 59)\n",
      "[TimeAffine.backward] return dx: (128, 10, 512)\n",
      "[TimeAttention.backward] dout: (128, 10, 256)\n",
      "[Trainer] batch_x: (128, 29)\n",
      "[Trainer] batch_t: (128, 11)\n",
      "[Seq2seq.forward] xs: (128, 29), ts: (128, 11)\n",
      "[AttentionDecoder.forward] out: (128, 10, 16)\n",
      "[AttentionDecoder.forward] dec_hs: (128, 10, 256) <- この長さが理想の10倍だった\n",
      "[AttentionDecoder.forward] c: (128, 10, 256)\n",
      "[AttentionDecoder.forward] out: (128, 10, 512)\n",
      "[TimeAffine.forward] x: (128, 10, 512)\n",
      "[TimeAffine.forward] rx: (1280, 512)\n",
      "[TimeAffine.forward] return: (128, 10, 59)\n",
      "[AttentionDecoder.forward] score: (128, 10, 59)\n",
      "[TimeSoftmaxWithLoss] xs: (128, 10, 59)\n",
      "[Seq2seq] dout: (128, 10, 59)\n",
      "[TimeAffine.backward] return dx: (128, 10, 512)\n",
      "[TimeAttention.backward] dout: (128, 10, 256)\n",
      "[Trainer] batch_x: (128, 29)\n",
      "[Trainer] batch_t: (128, 11)\n",
      "[Seq2seq.forward] xs: (128, 29), ts: (128, 11)\n",
      "[AttentionDecoder.forward] out: (128, 10, 16)\n",
      "[AttentionDecoder.forward] dec_hs: (128, 10, 256) <- この長さが理想の10倍だった\n",
      "[AttentionDecoder.forward] c: (128, 10, 256)\n",
      "[AttentionDecoder.forward] out: (128, 10, 512)\n",
      "[TimeAffine.forward] x: (128, 10, 512)\n",
      "[TimeAffine.forward] rx: (1280, 512)\n",
      "[TimeAffine.forward] return: (128, 10, 59)\n",
      "[AttentionDecoder.forward] score: (128, 10, 59)\n",
      "[TimeSoftmaxWithLoss] xs: (128, 10, 59)\n",
      "[Seq2seq] dout: (128, 10, 59)\n",
      "[TimeAffine.backward] return dx: (128, 10, 512)\n",
      "[TimeAttention.backward] dout: (128, 10, 256)\n",
      "[Trainer] batch_x: (128, 29)\n",
      "[Trainer] batch_t: (128, 11)\n",
      "[Seq2seq.forward] xs: (128, 29), ts: (128, 11)\n",
      "[AttentionDecoder.forward] out: (128, 10, 16)\n",
      "[AttentionDecoder.forward] dec_hs: (128, 10, 256) <- この長さが理想の10倍だった\n",
      "[AttentionDecoder.forward] c: (128, 10, 256)\n",
      "[AttentionDecoder.forward] out: (128, 10, 512)\n",
      "[TimeAffine.forward] x: (128, 10, 512)\n",
      "[TimeAffine.forward] rx: (1280, 512)\n",
      "[TimeAffine.forward] return: (128, 10, 59)\n",
      "[AttentionDecoder.forward] score: (128, 10, 59)\n",
      "[TimeSoftmaxWithLoss] xs: (128, 10, 59)\n",
      "[Seq2seq] dout: (128, 10, 59)\n",
      "[TimeAffine.backward] return dx: (128, 10, 512)\n",
      "[TimeAttention.backward] dout: (128, 10, 256)\n",
      "[Trainer] batch_x: (128, 29)\n",
      "[Trainer] batch_t: (128, 11)\n",
      "[Seq2seq.forward] xs: (128, 29), ts: (128, 11)\n",
      "[AttentionDecoder.forward] out: (128, 10, 16)\n",
      "[AttentionDecoder.forward] dec_hs: (128, 10, 256) <- この長さが理想の10倍だった\n",
      "[AttentionDecoder.forward] c: (128, 10, 256)\n",
      "[AttentionDecoder.forward] out: (128, 10, 512)\n",
      "[TimeAffine.forward] x: (128, 10, 512)\n",
      "[TimeAffine.forward] rx: (1280, 512)\n",
      "[TimeAffine.forward] return: (128, 10, 59)\n",
      "[AttentionDecoder.forward] score: (128, 10, 59)\n",
      "[TimeSoftmaxWithLoss] xs: (128, 10, 59)\n",
      "[Seq2seq] dout: (128, 10, 59)\n",
      "[TimeAffine.backward] return dx: (128, 10, 512)\n",
      "[TimeAttention.backward] dout: (128, 10, 256)\n",
      "[Trainer] batch_x: (128, 29)\n",
      "[Trainer] batch_t: (128, 11)\n",
      "[Seq2seq.forward] xs: (128, 29), ts: (128, 11)\n",
      "[AttentionDecoder.forward] out: (128, 10, 16)\n",
      "[AttentionDecoder.forward] dec_hs: (128, 10, 256) <- この長さが理想の10倍だった\n",
      "[AttentionDecoder.forward] c: (128, 10, 256)\n",
      "[AttentionDecoder.forward] out: (128, 10, 512)\n",
      "[TimeAffine.forward] x: (128, 10, 512)\n",
      "[TimeAffine.forward] rx: (1280, 512)\n",
      "[TimeAffine.forward] return: (128, 10, 59)\n",
      "[AttentionDecoder.forward] score: (128, 10, 59)\n",
      "[TimeSoftmaxWithLoss] xs: (128, 10, 59)\n",
      "[Seq2seq] dout: (128, 10, 59)\n",
      "[TimeAffine.backward] return dx: (128, 10, 512)\n",
      "[TimeAttention.backward] dout: (128, 10, 256)\n",
      "[Trainer] batch_x: (128, 29)\n",
      "[Trainer] batch_t: (128, 11)\n",
      "[Seq2seq.forward] xs: (128, 29), ts: (128, 11)\n",
      "[AttentionDecoder.forward] out: (128, 10, 16)\n",
      "[AttentionDecoder.forward] dec_hs: (128, 10, 256) <- この長さが理想の10倍だった\n",
      "[AttentionDecoder.forward] c: (128, 10, 256)\n",
      "[AttentionDecoder.forward] out: (128, 10, 512)\n",
      "[TimeAffine.forward] x: (128, 10, 512)\n",
      "[TimeAffine.forward] rx: (1280, 512)\n",
      "[TimeAffine.forward] return: (128, 10, 59)\n",
      "[AttentionDecoder.forward] score: (128, 10, 59)\n",
      "[TimeSoftmaxWithLoss] xs: (128, 10, 59)\n",
      "[Seq2seq] dout: (128, 10, 59)\n",
      "[TimeAffine.backward] return dx: (128, 10, 512)\n",
      "[TimeAttention.backward] dout: (128, 10, 256)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:3\u001b[0m\n",
      "File \u001b[0;32m~/code-git-backup/zeroDL/zeroDL2/common/trainer.py:42\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, x, t, max_epoch, batch_size, max_grad, eval_interval)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# 勾配を求め、パラメータを更新\u001b[39;00m\n\u001b[1;32m     41\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(batch_x, batch_t)\n\u001b[0;32m---> 42\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m params, grads \u001b[38;5;241m=\u001b[39m remove_duplicate(model\u001b[38;5;241m.\u001b[39mparams, model\u001b[38;5;241m.\u001b[39mgrads)  \u001b[38;5;66;03m# 共有された重みを1つに集約\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/code-git-backup/zeroDL/zeroDL2/ch7/seq2seq.py:83\u001b[0m, in \u001b[0;36mSeq2seq.backward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Seq2seq] dout: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdout\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m dh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mbackward(dout)\n\u001b[0;32m---> 83\u001b[0m dout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dout\n",
      "File \u001b[0;32m~/code-git-backup/zeroDL/zeroDL2/attention.py:128\u001b[0m, in \u001b[0;36mAttentionEncoder.backward\u001b[0;34m(self, dhs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, dhs):\n\u001b[0;32m--> 128\u001b[0m     dout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdhs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     dout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed\u001b[38;5;241m.\u001b[39mbackward(dout)\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dout\n",
      "File \u001b[0;32m~/code-git-backup/zeroDL/zeroDL2/common/time_layers.py:212\u001b[0m, in \u001b[0;36mTimeLSTM.backward\u001b[0;34m(self, dhs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mrange\u001b[39m(T)):\n\u001b[1;32m    211\u001b[0m     layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[t]\n\u001b[0;32m--> 212\u001b[0m     dx, dh, dc \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdhs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m     dxs[:, t, :] \u001b[38;5;241m=\u001b[39m dx\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, grad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(layer\u001b[38;5;241m.\u001b[39mgrads):\n",
      "File \u001b[0;32m~/code-git-backup/zeroDL/zeroDL2/common/time_layers.py:164\u001b[0m, in \u001b[0;36mLSTM.backward\u001b[0;34m(self, dh_next, dc_next)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrads[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m db\n\u001b[1;32m    163\u001b[0m dx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(dA, Wx\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m--> 164\u001b[0m dh_prev \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dx, dh_prev, dc_prev\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "acc_list = []\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(x_train, t_train, max_epoch=1, batch_size=batch_size, max_grad=max_grad)\n",
    "    correct_num = 0\n",
    "    for i in range(len(x_test)):\n",
    "        question, correct = x_test[[i]], t_test[[i]]\n",
    "        verbose = i < 10\n",
    "        correct_num += eval_seq2seq(model, question, correct, id_to_char, verbose, is_reverse=True)\n",
    "\n",
    "    acc = float(correct_num) / len(x_test)\n",
    "    acc_list.append(acc)\n",
    "    print(\"val acc %.3f%%\" % (acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
